{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x)\n",
    "    print(device)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockD(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4 , stride, 1, bias=True, padding_mode='reflect'),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels, features = [64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,features[0],kernel_size=4, stride=2, padding=1, padding_mode='reflect'),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "        layers=[]\n",
    "        in_channels=features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(BlockD(in_channels, feature, stride=1 if features[-1]==feature else 2))\n",
    "            in_channels = feature\n",
    "        layers.append(nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode='reflect'))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.initial(x)\n",
    "        return torch.sigmoid(self.model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    x=torch.randn(5, 3, 256, 256)\n",
    "    model = Discriminator(in_channels=3)\n",
    "    preds = model(x)\n",
    "    print(preds.shape)\n",
    "\n",
    "# the output is a 70x70 patch-GAN\n",
    "# each pixel in the output 30x30 sees a patch of 70x70 in the input\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockG(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down = True, use_act = True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv= nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, padding_mode='reflect', **kwargs)\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True) if use_act else nn.Identity()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.Block= nn.Sequential(\n",
    "            BlockG(channels, channels, kernel_size=3, padding=1),\n",
    "            BlockG(channels, channels, use_act=False, kernel_size=3, padding=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.Block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_channels, num_features=64,residuals=9):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.down_blocks= nn.ModuleList(\n",
    "            [\n",
    "                BlockG(num_features, num_features*2, kernel_size=3, stride=2, padding=1),\n",
    "                BlockG(num_features*2, num_features*4, kernel_size=3, stride=2, padding=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_features*4) for _ in range(residuals)]\n",
    "        )\n",
    "\n",
    "        self.up_blocks = nn.ModuleList(\n",
    "            [\n",
    "                BlockG(num_features*4, num_features*2, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                BlockG(num_features*2, num_features, down=False, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.last = nn.Conv2d(num_features, img_channels, kernel_size=7, stride=1, padding=3, padding_mode='reflect')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        for layer in self.down_blocks:\n",
    "            x=layer(x)\n",
    "        for layer in self.residual_blocks:\n",
    "            x=layer(x)\n",
    "        for layer in self.up_blocks:\n",
    "            x=layer(x)\n",
    "        return torch.tanh(self.last(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    img_channels=3\n",
    "    img_size=256\n",
    "    x=torch.randn((2, img_channels, img_size, img_size))\n",
    "    gen = Generator(img_channels, 9)\n",
    "    # print(gen)\n",
    "    print(gen(x).shape)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"datasets/horse2zebra/train\"\n",
    "TEST_DIR = \"datasets/horse2zebra/test\"\n",
    "lr= 2e-4\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 0\n",
    "EPOCHS = 1\n",
    "LAMBDA_IDENTITY = 0\n",
    "LAMBDA_CYCLE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorseZebra(Dataset):\n",
    "    def __init__(self, horse_dir, zebra_dir, transform = None):\n",
    "        self.horse_dir = horse_dir\n",
    "        self.zebra_dir = zebra_dir\n",
    "        self.horse = os.listdir(horse_dir)\n",
    "        self.zebra = os.listdir(zebra_dir)\n",
    "        self.transform = transform\n",
    "        self.length = max(len(self.horse),len(self.zebra))\n",
    "\n",
    "    def __len__(self): \n",
    "           return self.length\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        zebra_img = self.zebra[index % len(self.zebra)]\n",
    "        horse_img = self.horse[index % len(self.horse)]\n",
    "        \n",
    "        zebra_img = np.array(Image.open(f\"{self.zebra_dir}/{zebra_img}\").convert(\"RGB\"))\n",
    "        horse_img = np.array(Image.open(f\"{self.horse_dir}/{horse_img}\").convert(\"RGB\"))\n",
    "        \n",
    "        if self.transform:\n",
    "            augmentations = self.transform(image = zebra_img, image0 = horse_img)\n",
    "            zebra_img = augmentations[\"image\"]\n",
    "            horse_img = augmentations[\"image0\"]\n",
    "\n",
    "        return zebra_img,horse_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_h = Discriminator(in_channels=3).to(device)\n",
    "disc_z = Discriminator(in_channels=3).to(device)\n",
    "gen_h = Generator(img_channels=3, residuals=9).to(device)\n",
    "gen_z = Generator(img_channels=3, residuals = 9).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_disc = optim.Adam(\n",
    "    list(disc_h.parameters()) + list(disc_z.parameters()),\n",
    "    lr = lr,\n",
    "    betas = (0.5,0.999)\n",
    ")\n",
    "opt_gen = optim.Adam(\n",
    "    list(gen_h.parameters()) + list(gen_z.parameters()),\n",
    "    lr = lr,\n",
    "    betas = (0.5,0.999)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = nn.L1Loss()\n",
    "mse = nn.MSELoss()\n",
    "image_list = []\n",
    "losses = [[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=256, height = 256),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.ColorJitter(p=0.1),\n",
    "        A.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5], max_pixel_value=255),\n",
    "        ToTensorV2()\n",
    "    ],\n",
    "    additional_targets={\"image0\":\"image\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HorseZebra(horse_dir=f\"{TRAIN_DIR}/horse_train\", zebra_dir=f\"{TRAIN_DIR}/zebra_train\", transform=transforms)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_disc(zebra, horse, disc_h, disc_z, gen_h, gen_z, mse):\n",
    "    fake_horse = gen_h(zebra)\n",
    "    d_h_real = disc_h(horse)\n",
    "    d_h_fake = disc_h(fake_horse.detach())\n",
    "    d_h_real_loss = mse(d_h_real, torch.ones_like(d_h_real))\n",
    "    d_h_fake_loss = mse(d_h_fake, torch.zeros_like(d_h_fake))\n",
    "    d_h_loss = d_h_fake_loss + d_h_real_loss\n",
    "\n",
    "    fake_zebra = gen_z(horse)\n",
    "    d_z_real = disc_z(zebra)\n",
    "    d_z_fake = disc_z(fake_zebra.detach())\n",
    "    d_z_real_loss = mse(d_z_real, torch.ones_like(d_z_real))\n",
    "    d_z_fake_loss = mse(d_z_fake, torch.zeros_like(d_z_fake))\n",
    "    d_z_loss = d_z_fake_loss + d_z_real_loss\n",
    "\n",
    "    d_loss = (d_z_loss + d_h_loss)/2\n",
    "\n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(zebra, horse, disc_h, disc_z, gen_h, gen_z, L1, mse):\n",
    "    # Adversarial loss\n",
    "    fake_horse = gen_h(zebra)\n",
    "    d_h_fake = disc_h(fake_horse)\n",
    "    g_h_loss = mse(d_h_fake, torch.ones_like(d_h_fake))\n",
    "\n",
    "    fake_zebra = gen_z(horse)\n",
    "    d_z_fake = disc_z(fake_zebra)\n",
    "    g_z_loss = mse(d_z_fake, torch.ones_like(d_z_fake))\n",
    "\n",
    "    adv_loss = g_h_loss + g_z_loss\n",
    "\n",
    "    # Cycle Loss\n",
    "    cycle_zebra = gen_z(fake_horse)\n",
    "    cycle_horse = gen_h(fake_zebra)\n",
    "    c_h_loss = L1(horse, cycle_horse)\n",
    "    c_z_loss = L1(zebra, cycle_zebra)\n",
    "\n",
    "    cycle_loss = c_h_loss + c_z_loss\n",
    "    \n",
    "    # Identity Loss\n",
    "    identity_zebra = gen_z(zebra)\n",
    "    identity_horse = gen_h(horse)\n",
    "    i_z_loss = L1(zebra, identity_zebra)\n",
    "    i_h_loss = L1(horse, identity_horse)\n",
    "\n",
    "    identity_loss = i_h_loss + i_z_loss\n",
    "\n",
    "    g_loss = adv_loss + cycle_loss * LAMBDA_CYCLE + identity_loss * LAMBDA_IDENTITY\n",
    "\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(disc_h, disc_z, gen_h, gen_z, loader, opt_disc, opt_gen, L1, mse):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for idx, (zebra, horse) in enumerate(loop):\n",
    "        zebra = zebra.to(device)\n",
    "        horse = horse.to(device)\n",
    "\n",
    "        d_loss = train_disc(zebra, horse, disc_h, disc_z, gen_h, gen_z, mse)\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        d_loss.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        g_loss = train_gen(zebra, horse, disc_h, disc_z, gen_h, gen_z, L1, mse)\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        g_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "    fake_horse = gen_h(zebra)\n",
    "    fake_zebra = gen_z(horse)\n",
    "    image_list.append([horse*0.5+ 0.5, fake_horse*0.5 + 0.5, zebra*0.5 + 0.5, fake_zebra*0.5 + 0.5])\n",
    "    losses[0].append(d_loss.item())\n",
    "    losses[1].append(g_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 278/1334 [20:51<1:19:15,  4.50s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisc_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisc_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_disc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m],  D_loss : \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m,   G_loss : \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, EPOCHS, losses[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], losses[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(disc_h, disc_z, gen_h, gen_z, loader, opt_disc, opt_gen, L1, mse)\u001b[0m\n\u001b[1;32m     13\u001b[0m     g_loss \u001b[38;5;241m=\u001b[39m train_gen(zebra, horse, disc_h, disc_z, gen_h, gen_z, L1, mse)\n\u001b[1;32m     15\u001b[0m     opt_gen\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     opt_gen\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m fake_horse \u001b[38;5;241m=\u001b[39m gen_h(zebra)\n",
      "File \u001b[0;32m~/ENTER/envs/torch/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ENTER/envs/torch/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ENTER/envs/torch/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(disc_h, disc_z, gen_h, gen_z, loader, opt_disc, opt_gen, L1, mse)\n",
    "    print(\"Epoch [{}/{}],  D_loss : {:.4f},   G_loss : {:.4f}\".format(epoch+1, EPOCHS, losses[0][-1], losses[1][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[0], '-')\n",
    "plt.plot(losses[1], '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Discriminator', 'Generator'])\n",
    "plt.title('Losses');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(image_list, nrows = EPOCHS, ncols = 4):\n",
    "    plt.subplots(nrows, ncols, figsize=(ncols*3 ,nrows*3))\n",
    "    for (i, imgs) in enumerate(image_list):\n",
    "            for j in range(1,ncols+1):\n",
    "                plt.subplot(nrows, ncols, ncols*i+j)\n",
    "                plt.imshow(imgs[j-1].cpu().detach().squeeze().numpy().transpose(1, 2, 0))\n",
    "                plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(image_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
